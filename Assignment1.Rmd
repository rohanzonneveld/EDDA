---
title: "Assignment 1 - Group 27"
author: "Joost Driessen, Emma van Lipzig, Rohan Zonneveld"
output: pdf_document
date: "`r Sys.Date()`"
theme: sandstone 
highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
library(ggplot2)
library(readr)
library(gridExtra)
library(viridis)
library(reshape2)   
library(dplyr)
```

# Excercise 1. Birthweight

# Intro

mydata <- read.table("birthweight.txt", header = TRUE, sep = "\n")
mu <- mean(mydata$birthweight)
sigma = sd(mydata$birthweight)
sigma
# mu = 2913.293 g, sigma = 697.5002

# Exercise 1: a

shapiro.test(mydata$birthweight)
# W = 0.99595, pvalue = 0.8995, which means the Shapiro-Wilk test supports normality
qqnorm(mydata$birthweight)
hist(mydata$birthweight)
# Both the Shapiro-Wilk test and the plots support normality

n <- length(mydata$birthweight)
alpha <- 0.04
t_value <- qt(1-alpha/2, df=n-1)
t_value
lower_bound <- mu - t_value*sigma/sqrt(n)
upper_bound <- mu + t_value*sigma/sqrt(n)
# The 96% confidence interval lies between 2808.084 g and 3018.501 g.

library(boot)
boot_fn <- function(data, index) mean(data[index])
boot_data <- boot(mydata$birthweight, boot_fn, R=1000)
quantile(boot_data$t, c(0.02, 0.98))

# The 96% confidence interval using bootstrap lies between 2807.927 and 3018.938
# These two confidence intervals are very similar. Normally a bootstrapped CI is constructed
# because of non-normality or outliers, but this data is distributed normally, so the
# bootstrap yields the same results as the regular method.

# Exercise 1: b

t.test(mydata$birthweight, mu = 2800, alternative = 'greater')

# This t-test supports the expert's claim that the mean birthweight is higher than 2800 g,
# since the CI is entirely above this value. 

num_above <- sum(mydata$birthweight > 2800)
num_below <- sum(mydata$birthweight < 2800)

# Perform the sign test
binom.test(num_above, num_above + num_below, p = 0.5, alternative = "greater")

# The sign test too indicates that the expert's claim was right, since p < 0.05.

# Exercise 1: c

library(pwr)
sig.level <- 0.05 
effect.size <- (2913.293 - 2800) / sigma 
power_t <- pwr.t.test(n = n, d = effect.size, sig.level = sig.level, type = "one.sample", alternative = "greater")$power
birthweight <- c(2786, 2977, 3076, 3277, 2826, 3106, 3016, 3131, 2846, 3011)
#------------------------------------------------------------------------------
# TODO: Write down the power
# -----------------------------------------------------------------------------

# Exercise 1: d

proportion_under2600 <- sum(mydata$birthweight < 2600)/n
# So now we know the proportion of babies born under 2600 gram. If we take the distance from
# this mean to 0.25 and apply that same distance in the positive direction we get the 
# complete confidence interval.
distance <- proportion_under2600 - 0.25
CI <- c(0.25, proportion_under2600 + distance)
# The true proportion of babies born under 2600 grams lies between 25% and 40.9% of the population

#-------------------------------------------------------------
# Question: How to calculate confidence level?
# ------------------------------------------------------------

# Exercise 1: e

# pmu2600 <- 34/62
# pfu2600 <- 28/62
# pma2600 <- 61/126
# pfa2600 <- 65/126
# 
# birthweights_below_2600 <- c()
# birthweights_above_2600 <- c()
# 
# for (i in 1:length(mydata$birthweight)) {
#   if (mydata$birthweight[i] < 2600) {
#     birthweights_below_2600 <- c(birthweights_below_2600, mydata$birthweight[i])
#   }
#   else birthweights_above_2600 <- c(birthweights_above_2600, mydata$birthweight[i])
# }
# 
# # print the new dataset
# mean_male_weight <- (mean(birthweights_below_2600) * 34 + mean(birthweights_above_2600) * 61)/(61 + 34)
# mean_female_weight <- (mean(birthweights_below_2600) * 28 + mean(birthweights_above_2600) * 65)/(65 + 28)
# sd_male_below_2600 <- sqrt(sum((birthweights_below_2600 - mean_male_weight)^2) / 33)
# print(sd_male_below_2600)
# print(mean_female_weight)
# print(mean_male_weight)

prop.test(c(34,28),c(95, 93))
prop.test(c(61,65),c(95,90))

# These proportianality tests suggest that there is no significant difference between 
# the sample proportions of the two groups, which mean that there is no significant difference
# between the mean male birthweight and mean female birthweight.





# Excercise 2. Cholesterol
## a)
```{r load data 2, echo=FALSE}
data=read.table(file="cholesterol.txt",header=TRUE)
Before = data$Before
After8weeks = data$After8weeks
```
We summarise the data by giving a summary and by making a histogram, a boxplot and a QQ-plot of both columns.

### Before Diet

```{r summarise Before, fig.height=2, fig.width=6, echo=FALSE}
par(mfrow=c(1,3))

summary(Before)

hist(Before,xlab='cholesterol', main='Histogram')
boxplot(Before, ylab='cholesterol')
qqnorm(Before)
```


### After 8 weeks of diet

```{r summarise After8weeks, fig.height=2, fig.width=6, echo=FALSE}
par(mfrow=c(1,3))

summary(After8weeks)
hist(After8weeks, xlab='cholesterol', main='Histogram')
boxplot(After8weeks, ylab='cholesterol')
qqnorm(After8weeks)

par(mfrow=c(1,1))
```

Both histograms look normally distributed, the boxplots are symmetrical with the mean in the center of the box and the QQ-plots are linear. In conclusion, the plots give no reason to suspect that the data is drawn from a non-normal distribution. 

To investigate if the columns are correlated we calculate the correlation according to the literature. To visualize the correlation a plot is created with before on the x-axis and after8weeks on the y-axis.

```{r correlation, echo=TRUE}
cor(Before,After8weeks)
```
```{r, fig.height=3, fig.width=3, echo=FALSE}
plot(Before,After8weeks)
```

The columns are strongly correlated.

## b)
Since the study measured two sets of observations obtained from the same individuals the data is paired. In this case, each individual's before and after cholesterol levels are paired observations. Two relevant statistical tests for paired samples are: paired t-test and Wilcoxon signed-rank test.

A *paired t-test* is performed when the data is normally distributed. Looking back to *a)* we can see that the data is indeed normally distributed. 
```{r t-test, echo=TRUE}
p=t.test(After8weeks, Before, paired = TRUE)[[3]]; p
```
The p-value is lower than 0.05, which means H0 can be rejected meaning that there is indeed a true difference in means between the two variables.

The *Wilcoxon signed-rank test* does not assume that the data is normally distributed and is therefore a useful alternative to the paired t-test when this assumption is violated.

```{r wilcoxon signed rank test, echo=TRUE}
p=wilcox.test(After8weeks, Before, paired = TRUE)[[3]]; p
```

The p-value is lower than 0.05, so H0 is rejected meaning that the true location of the population is different between columns.

Since the data is paired, we can apply a permutation test to determine whether the diet has an effect. Also, the permutation test does not assume any distribution for the data. The R code to perform this test is as follows:
```{r permutation test, echo=TRUE}
mystat=function(x,y) {mean(x-y)}
B=1000; tstar=numeric(B)
for (i in 1:B) {
  dietstar=t(apply(cbind(After8weeks,Before),1,sample))
  tstar[i]=mystat(dietstar[,1],dietstar[,2]) }
myt=mystat(After8weeks,Before)

myt
```
In the histogram below the distribution of t* is depicted. The distribution is normal, due to CLT. The actual value of the T statistic is depicted in red. 

```{r tstar histogram, fig.height=3, fig.width=7, echo=FALSE}
hist(tstar, xlim=c(-0.7,0.7))
lines(rep(myt,2),c(0,20), col="red",lwd=2)
```
```{r calculate p-value, echo=TRUE}
pl=sum(tstar<myt)/B
pr=sum(tstar>myt)/B
p=2*min(pl,pr); p
```
The value of p is equal to zero, which means H0 can be rejected. This means that there is a significant difference between before and after the diet.

## c)

The mean of a uniform sample is given by $E[\bar{X}] = (1/n) * \sum{Xi} = 1/18 * \sum{Xi}$.The variation of a uniform sample is also given, $Var(Xi) = ((\theta - 3)^2)/12$. So the variance of the sample mean is given by $Var(\bar{X}) = Var((1/18) * \sum{Xi}) = (1/18^2) * \sum Var(Xi) = ((\theta - 3)^2)/(12 * 18 * 18)$. According to the central limit theorem, as n goes to infinity, the distribution of $\bar{X}$ approaches a normal distribution with mean $E[\bar{X}]$ and variance $Var(\bar{X})$. The mean of a uniform distribution is in the center, so to estimate the maximum of a uniform distribution ($\bar{\theta}$) one can simply multiply the mean by 2 and subtract the start of the interval.  
```{r estimate theta, echo=TRUE}
x.bar = mean(After8weeks)
theta.hat = 2 * x.bar - 3
```
A 95% confidence interval for $\theta$ is found using the central limit theorem by calculating the margin of error and adding and subtracting it to $\bar{\theta}$.
```{r calculate CI, echo=TRUE}
z = qnorm(0.975) 
sigma = sqrt(((theta.hat - 3)^2)/(12*18))
me = z * sigma

ci = c(theta.hat - me, theta.hat + me)
ci
```

**Can you improve this CI?**

## d)

```{r histogram After8weeks, echo=FALSE}
hist(After8weeks, freq = FALSE, xlim = c(3, 12))
curve(dunif(x, min = 3, max = 12), add = TRUE, col="blue", lwd = 2)
```

The After8weeks column does not appear to be uniformly distributed. Since there are no values bigger than 8 in the data it is expected that values of $\theta>8$ will reject the null hypothesis. To investigate if After8weeks is drawn from an uniform distribution in [3,$\theta$] a bootstrap test is performed. Surrogate T-values are generated that are representative of values of T under H0. The test statistic (in this case the maximum) is computed. This process is repeated 1000 times. Finally, the T-value is compared to the surrogate T*-values to determine a p-value. 


```{r bootstrap test, echo=TRUE}
H0=rep(1, 9)
for(theta in 4:12){
  n=length(After8weeks); t=max(After8weeks)
  B=1000; Tstar=numeric(B)
  for(i in 1:B) {
   Xstar=runif(n,3,theta)
   Tstar[i]=max(Xstar)}
  pl=sum(Tstar<t)/B;pr=sum(Tstar>t)/B
  p=2*min(pl,pr)
  if(p<0.05){H0[theta-3]=0}}
H0
```

The H0 is rejected for all values of $\theta$ except 8. This result was to be expected as the data ranges from 3 to 8 as can be seen in the histogram.

The *Kolmogorov-Smirnov* is used to test if two samples are from the same distribution. The actual data can be compared to data generated from a uniform distribution. So it is perfectly suited to use in this situation.

```{r KS-test, echo=TRUE}
H0=rep(1,9)
for(theta in 4:12){
  n=length(After8weeks)
  sample=runif(n,3,theta)
  p=ks.test(After8weeks,sample)$p.value
  if(p<0.05){H0[theta-3]=0}
}
H0
```
The null hypothesis is rejected in cases where $\theta$<8.

## e)
To test whether the median cholesterol level after 8 weeks of low fat diet is less than 6 a *Wilcoxon signed-rank test* is performed.
```{r wilcoxon signed-rank test, warning=FALSE}
p=wilcox.test(After8weeks,mu=6,alt="l")[[3]]; p
```
The p-value is bigger than 0.05 so the null hypothesis can not be rejected. This means that it is not statistically significant that the population median is lower than 6.

```{r calculate proportion, echo=TRUE}
n=sum(After8weeks<4.5)
prop=n/length(After8weeks);prop
```
The proportion of the values lower than 4.5 is less than 25%

# Excercise 3. Diet
To investigate the effect of 3 types of diet, 78 persons were divided randomly in 3 groups, the first group following diet 1, second group diet 2 and the third group diet 3. Next to some other characteristics, the weight was measured before diet and after 6 weeks of diet for each person in the study. The collected data is summarized in the data frame diet.txt Download diet.txt with the following columns: person – participant number, gender – gender (1 = male, 0 = female), age – age (years), height – height (cm), preweight – weight before the diet (kg), diet – the type of diet followed, weight6weeks – weight after 6 weeks of diet (kg). Compute and add to the data frame the variable weight.lost expressing the lost weight, to be used as response variable.

```{r load data 3}
data <- read.table(file= 'diet.txt', header=TRUE)
#View(data)
```

```{r add data 3}
data$weight.lost <- 0
for (i in 1:78) {
  data$weight.lost[i] <- data$preweight[i] - data$weight6weeks[i]
}
head(data) #shows that weight.lost column has been added
summary(data) #inspect data
```


## a)
Make an informative graphical summary of the data relevant for study of the effect of diet on the weight loss. By using only the columns preweight and weight6weeks, test the claim that the diet affects the weight loss. Check the assumptions of the test applied.

The qqplot and histogram of the weigth before diet show that this data does not appear to be normally distributed, as there is one large outlier of 103. The same goes for the weight after six weeks, so after the diet. This again does not seem normally distributed because of the outlier 103. However, the differences between the two, represented as weight.lost, do appear to be distributed normally. This can be seen in both the QQ plot and histogram. 
```{graphical summaries - normality}
qq_pre <- ggplot(data) + geom_qq(aes(sample=preweight)) + theme_light() + labs(title="QQ plot Preweight")
qq_post <- ggplot(data) + geom_qq(aes(sample=weight6weeks))  + theme_light()  + labs(title="QQ plot Weight after six weeks")

hist_pre <- ggplot(data, aes(x=preweight))+ geom_histogram(binwidth=1, color="seagreen", fill="lightgreen", linewidth=.3) + theme_light() + labs(title="Histogram Preweight")
hist_post <- ggplot(data, aes(x=weight6weeks))+ geom_histogram(binwidth=1, color="seagreen", fill="lightgreen", linewidth=.3) + theme_light() + labs(title="Histogram Weight after six weeks")

grid.arrange(qq_pre, hist_pre, qq_post, hist_post)

max(data$preweight)
max(data$weight6weeks)

qq_diff <- ggplot(data) + geom_qq(aes(sample=weight.lost)) + theme_light() + labs(title="QQ plot Lost weight") 
hist_diff <- ggplot(data, aes(x=weight.lost))+ geom_histogram(binwidth=1, color="seagreen", fill="lightgreen", linewidth=.3) + theme_light() + labs(title="Histogram Lost weight")

grid.arrange(qq_diff, hist_diff)

```

The Shapiro-Wilk test does not reject normality (if we take alpha = 0.05), for the preweight data. As this test does not always reject normality for non-normal distributions, this distribution may still be non-normal (as indicated by the histogram and qqplot).

The Shapiro-Wilk test rejects normality (if we take alpha = 0.05), for the weight at six weeks data. When this test rejects normality, the distribution should indeed be non-normal, which corresponds with the qqplot and histogram of the data.
```{test - normality}
shapiro.test(data$preweight)
shapiro.test(data$weight6weeks)
```

The boxplots below shows that there may be a difference in the weight before and after dieting. The first boxplot shows the distribution of weight data before and after a diet, the second boxplot shows the distribution of the difference between these weights, which is the distribution of the weight loss. 
```{graphical summaries - data against each other}
data_subset <- select(data,preweight, weight6weeks)
data_long <- melt(data_subset)

weight_boxplt <- ggplot(data_long, aes(x = variable, y = value)) +         
  geom_boxplot(color="seagreen", fill="lightgreen") + labs(title = 'Weights before and after diet', x = 'diet stage', y = 'weight')+ theme_light()

diet_boxplt <- ggplot(data, aes( y=weight.lost)) + geom_boxplot(color="seagreen", fill="lightgreen") + labs(title='Weight lost') + theme_light()

grid.arrange(weight_boxplt, diet_boxplt,  ncol = 2)

```


Because the differences between the pre and post diet weight data is distributed normally, a t-test can be used to determine whether these two groups differ statistically significantly from each other. Because the data is the pre and post weight from the same subjects, in this situation a paired t-test is applicable. H0 is that the groups are not different.
```{r t test}
t.test(data$preweight, data$weight6weeks, data = data, paired = TRUE)
```
The p value of the t-test is < 0.05, therefore H0 is rejected. This means that the means of preweight and weight6weeks statistically differ. As the weightloss over the six weeks of dieting was significant, it could be that diet has an influence on weightloss. However, this does not take into account other factors included in the experiment like gender and age.

## b)
Apply one-way ANOVA to test whether type of diet has an effect on the lost weight. Do all three types diets lead to weight loss? Which diet was the best for losing weight? Can the Kruskal-Wallis test be applied for this situation?

The boxplots below show that that different diets may have different effects on weightloss.  
```{graphical summaries - ANOVA}
diet_g_boxplt <- ggplot(data, aes( y=weight.lost, group = diet)) + geom_boxplot(color="seagreen", fill="lightgreen") + labs(title='Weight lost per diet') + theme_light()
diet_g_boxplt
```

The summary below shows that the study is not a balanced design. Diet 1 has less participants than diet 2 and 3. 

The ANOVA with treatment parametrization and diet 1 as base level shows that the other diets differ significantly from diet 1. This means that some diets are more effective for weightloss than others. If the study had a 'no diet' treatment, this would have been a good base level to use, however, this is not the case. As it is not clear which of the diets should be the base level, it is better to use sum parametrization. A summary of the treatment parametrization model shows that diet 3 is better for weightloss than diet 1. A summary of the model with sum parametrization shows that diet 2 differs significantly from the global diet mean. Although all diets can be used for weightloss, diet 2 and 3 are better than diet 1. A t-test shows that diet 2 and 3 are significantly different, which implies that diet 3 is best for losing weight. 
```{r ANOVA}
data$diet <- as.factor(data$diet) # diet is numerical but needs to be factor for ANOVA
is.factor(data$diet) # True
summary(data$diet) #design is not balanced

# treatment parametrization, diet1 is base level
dietaov <- lm(weight.lost ~ diet, data=data)
anova(dietaov)
summary(dietaov)

# sum parametrization
contrasts(data$diet)=contr.sum
dietaov2 <- lm(weight.lost ~ diet, data=data)
anova(dietaov2)
summary(dietaov2)

# t-test
data_diet2 <- data[data$diet == 2,]
data_diet3 <- data[data$diet == 3,]
names(data_diet3)[8]<- paste("weight.lost2")
data_diet23 <- cbind(data_diet2,data_diet3)
t.test(data_diet23$weight.lost, data_diet23$weight.lost2, data = data_diet23, paired = FALSE)
```

Below the model assumptions for the two ANOVA's are tested. The qqplots show that the residuals for both models seem normally distributed, and neither plot of the fitted against actual residuals shows particular patterns. Therefore the model assumptions are met for both ANOVA's. Because these assumptions are met, a non-parametric test like Kruskall-Wallis would be weaker to use. This is based on ranks, which means a lot of information is thrown out when using Kruskal-Wallis. It is still possible to use this test, but in this case it would not provide better insights than ANOVA. 
```{r ANOVA normality}
qq_aovres1 <- ggplot(data) + geom_qq(aes(sample=residuals(dietaov)))  + theme_light()  + labs(title="QQ residuals of lm weight.lost ~ diet")
scatter_aovres1 <- ggplot(dietaov, aes(fitted(dietaov), residuals(dietaov))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet")

grid.arrange(qq_aovres1, scatter_aovres1, ncol=2)

qq_aov2res2 <- ggplot(data) + geom_qq(aes(sample=residuals(dietaov2)))  + theme_light()  + labs(title="QQ residuals of lm weight.lost ~ diet")
scatter_aov2res2 <- ggplot(dietaov2, aes(fitted(dietaov2), residuals(dietaov2))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet")

grid.arrange(qq_aov2res2, scatter_aov2res2, ncol=2)
```


## c)
Use two-way ANOVA to investigate effect of the diet and gender (and possible interaction) on the lost weight.

The two-way ANOVAs below show a main effect of diet on weight loss, no main effect of gender on weight loss and an interaction effect between gender and diet on weight loss. The factor diet is sum parametrized because there is no clear reason to pick one of the diets as a base level. 
```{r two way ANOVA gender}
data$gender <- as.factor(data$gender)
is.factor(data$gender) # TRUE

genderaovm <- lm(weight.lost ~ diet + gender, data = data) # main effects
anova(genderaovm)

genderaovi <- lm(weight.lost ~ diet * gender, data = data) # interaction effects
anova(genderaovi)
```


The interaction plots show that indeed diet matters a lot. The specifically for diet 2 and 3 the difference between the genders is very pronounced. It looks like gender matters less as the lines for diet 1 and 2 look somewhat similar, but the line for diet 3 is very different.
```{r interaction plots gender}
par(mfrow=c(1,2))
interaction.plot(data$gender, data$diet, data$weight.lost)
interaction.plot(data$diet, data$gender, data$weight.lost)
```

Both the fitted against actual residual plot and qq residual plot indicate that the additive model does not violate the assumption of normality. However, the spread of the residuals looks different in the last column from the other columns for the interaction model. The QQ residual plot also does not look completely normal. Therefore it is doubtful that the assumption of normality is met for the interaction model. 
```{r two way anova gender normality }
par(mfrow=c(1,2))
qqnorm(residuals(genderaovm))
scatter_genderaovm <- ggplot(genderaovm, aes(fitted(genderaovm), residuals(genderaovm))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet + gender")

qqnorm(residuals(genderaovi))
scatter_genderaovi <- ggplot(genderaovi, aes(fitted(genderaovi), residuals(genderaovi))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet * gender")

grid.arrange(scatter_genderaovm, scatter_genderaovi, ncol=2)

```

## d)  
Apply an appropriate model to investigate effects of diet and height (and possibly their interaction) on the lost weight. Is the effect of height the same for all 3 types of diet?


The two-way ANOVAs below show a main effect of diet on weight loss, no main effect of height on weight loss and no interaction effect between height and diet on weight loss. The factor diet is sum parametrized because there is no clear reason to pick one of the diets as a base level. 
```{r two way ANOVA height}
data$height <- as.factor(data$height)
is.factor(data$height) # TRUE

heightaovm <- lm(weight.lost ~ diet + height, data = data) # main effects
anova(heightaovm)

heightaovi <- lm(weight.lost ~ diet * height, data = data) # interaction effects
anova(heightaovi)
```


The interaction plots show that lines where diet is fixed vary a lot. No interaction effect and no main effect of height was found, so this variebility is probably because of noise. Some lines where height is fixed behave similarly, but there are also lines which look very different, mostly for diet 2 and 3 they are very spread. 
```{r interaction plots height}
par(mfrow=c(1,2))
interaction.plot(data$height, data$diet, data$weight.lost)
interaction.plot(data$diet, data$height, data$weight.lost)
```

QQ residual plots of the main effect and the interaction models show that both models violate the assumption of normality, which can also be seen om tje fitted against actual residual plots, where there are systematic spread differences.  
```{r two way anova height normality }
par(mfrow=c(1,2))
qqnorm(residuals(heightaovm))
scatter_heightaovm <- ggplot(heightaovm, aes(fitted(heightaovm), residuals(heightaovm))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet + height")

qqnorm(residuals(heightaovi))
scatter_heightaovi <- ggplot(heightaovi, aes(fitted(heightaovi), residuals(heightaovi))) + geom_point() + theme_light() + labs(title="Fitted against actual residuals of lm weight.lost ~ diet * height")

grid.arrange(scatter_heightaovm, scatter_heightaovi, ncol=2)

```

###Is the effect of height the same for all 3 types of diet?

# e)
Which of the two approaches, the one from b) or the one from d), do you prefer? Why? For the preferred model, predict the lost weight for all three types of diet for an average person.

## Excercise 4. Yield of peas




